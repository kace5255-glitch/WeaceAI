const express = require('express');
const router = express.Router();
const { GoogleGenerativeAI } = require('@google/generative-ai');
const OpenAI = require('openai');

// --- Configuration & Initialization ---
const apiKey = process.env.GOOGLE_API_KEY || process.env.VITE_GOOGLE_API_KEY || process.env.API_KEY;
const genAI = new GoogleGenerativeAI(apiKey);

// DeepSeek Client (Reasoning/Logic/Briefing)
const deepseekApiKey = process.env.DEEPSEEK_API_KEY;
let deepseek = null;
if (deepseekApiKey) {
    deepseek = new OpenAI({
        apiKey: deepseekApiKey,
        baseURL: 'https://api.deepseek.com'
    });
}

// Qwen Client (Production/Creative Writing)
const qwenApiKey = process.env.QWEN_API_KEY;
let qwen = null;
if (qwenApiKey) {
    qwen = new OpenAI({
        apiKey: qwenApiKey,
        baseURL: 'https://dashscope-intl.aliyuncs.com/compatible-mode/v1'
    });
}

// --- Helper Functions ---

// 1. Context Builder: The "Smart Memory" Core
// Fetches S-Level (Critical), A-Level (Volume), and Recent Briefings
async function buildChatContext(supabase, novelId, currentChapterId, mode = 'standard') {
    let context = "";

    // Safety check: if no novelId, return empty context
    if (!novelId) return "";

    try {
        // A. Load S-Level (Critical Global) Briefings
        // These are the "Core Mysteries" or "Main Plot Points" that must never be forgotten.
        const { data: sBriefings } = await supabase
            .from('chapter_briefings')
            .select(`
                content, 
                chapters:chapter_id (title, volume_id)
            `)
            .eq('priority_level', 'S')
            // Note: In real production, we'd filter by novelId more efficiently. 
            // Here assuming briefings belong to chapters of the novel.
            .limit(10); // Safety limit

        if (sBriefings && sBriefings.length > 0) {
            context += `\n„Äêüî• Ê†∏ÂøÉ‰ºèÁ≠ÜËàá‰∏ªÁ∑öË®òÊÜ∂ (S-Level)„Äë\n${sBriefings.map(b => `[${b.chapters?.title || 'Êú™Áü•Á´†ÁØÄ'}]: ${b.content}`).join('\n')}\n`;
        }

        // B. Load A-Level (Current Volume) Briefings
        if (currentChapterId) {
            const { data: currentChapter } = await supabase
                .from('chapters')
                .select('volume_id, title')
                .eq('id', currentChapterId)
                .single();

            if (currentChapter?.volume_id) {
                // Get chapters in current volume first
                const { data: volChapters } = await supabase.from('chapters').select('id').eq('volume_id', currentChapter.volume_id);
                const volChapIds = volChapters?.map(c => c.id) || [];

                if (volChapIds.length > 0) {
                    const { data: volumeBriefings } = await supabase
                        .from('chapter_briefings')
                        .select('content, priority_level')
                        .in('chapter_id', volChapIds)
                        .in('priority_level', ['A', 'B']) // Get A and B for current volume
                        .limit(20);

                    const aLevels = volumeBriefings?.filter(b => b.priority_level === 'A') || [];

                    if (aLevels.length > 0) {
                        context += `\n„Äêüìñ Êú¨Âç∑ÈáçË¶Å‰∫ã‰ª∂ (A-Level)„Äë\n${aLevels.map(b => b.content).join('\n')}\n`;
                    }
                }
            }

            // C. Current Chapter Content (Standard/Detailed Mode)
            if (mode === 'standard' || mode === 'deep') {
                const { data: fullChapter } = await supabase
                    .from('chapters')
                    .select('content')
                    .eq('id', currentChapterId)
                    .single();

                if (fullChapter?.content) {
                    const text = fullChapter.content;
                    const truncated = text.length > 2000 ? `...(ÂâçÊñáÁúÅÁï•)\n${text.slice(-2000)}` : text;
                    context += `\n„Äêüìç Áï∂ÂâçÊí∞ÂØ´ÂÖßÂÆπ (ÁâáÊÆµ)„Äë\n${truncated}\n`;
                }
            }
        }

        return context;
    } catch (err) {
        console.warn("Context build warning:", err.message);
        return ""; // Fail gracefully
    }
}

// 2. System Persona Builder - The "Triple Persona" Logic & 10-15 Point Plot
function buildSystemPersona(personaType = 'editor') {
    const baseIdentity = `‰Ω†ÊòØ‰∏Ä‰ΩçÂÖºÂÖ∑„ÄåÈáë‰∏ªËÆÄËÄÖ„Äç„ÄÅ„ÄåÁôΩÈáë‰ΩúËÄÖ„ÄçËàá„ÄåÂö¥Ê†ºÁ∑®ËºØ„Äç‰∏âÂêà‰∏ÄË∫´‰ªΩÁöÑË∂ÖÁ¥öÂØ´‰ΩúÊê≠Ê™î„ÄÇ`;

    // Output Contract (The Hard Rules)
    const outputRules = `
„ÄêËº∏Âá∫Ë¶èÁØÑ (Output Contract)„Äë
1. Ë™ûË®ÄÔºöÁπÅÈ´î‰∏≠Êñá (Traditional Chinese)„ÄÇ
2. Ê†ºÂºèÔºöMarkdown Ê†ºÂºèÔºåÊ¢ùÁêÜÂàÜÊòé„ÄÇ‰∏çË¶Å‰ΩøÁî® XML Ê®ôÁ±§„ÄÇ
3. È¢®Ê†ºÔºöÁõ¥ÁôΩÊúâÂäõÔºåÊãíÁµïÈÅéÂ∫¶‰øÆËæ≠ËàáËß£ÈáãÊÄßÂª¢Ë©±„ÄÇ
`;

    let specificInstruction = "";

    switch (personaType) {
        case 'editor': // The logic checker
            specificInstruction = `
„ÄêÁï∂ÂâçÊ®°ÂºèÔºöüõ°Ô∏è Âö¥Ê†ºÁ∑®ËºØ (Editor)„Äë
‰Ω†ÁöÑ‰ªªÂãôÊòØ„ÄåÊâæÁ¢¥„ÄçËàá„ÄåÁ≥æÈåØ„Äç„ÄÇ
- Ê™¢Êü•ÈÇèËºØÊºèÊ¥ûÔºöËßíËâ≤Ë°åÁÇ∫ÊòØÂê¶Á¨¶Âêà‰∫∫Ë®≠ÔºüËÉΩÂäõÈ´îÁ≥ªÊòØÂê¶Â¥©Â£ûÔºü
- Ê™¢Êü•‰ºèÁ≠ÜÈñâÁí∞ÔºöÊòØÂê¶ÊúâÊú™ÂõûÊî∂ÁöÑ‰ºèÁ≠ÜÔºü
- Ê™¢Êü•ÁØÄÂ•èÔºöÊòØÂê¶Â§™ÊãñÊ≤ìÔºü
Ë´ãÁî®ÁäÄÂà©„ÄÅÂÆ¢ËßÄÁöÑË™ûÊ∞£ÊåáÂá∫ÂïèÈ°åÔºå‰∏¶Áµ¶Âá∫ÂÖ∑È´î‰øÆÊîπÂª∫Ë≠∞„ÄÇ‰∏çË¶ÅÂêπÊçß„ÄÇ`;
            break;

        case 'muse': // The creative partner
            specificInstruction = `
„ÄêÁï∂ÂâçÊ®°ÂºèÔºöüí° ÁÜ±ÊÉÖÁπÜÊÄù (Muse/Author)„Äë
‰Ω†ÁöÑ‰ªªÂãôÊòØ„ÄåÁôºÊï£„ÄçËàá„ÄåÂÖ±Ââµ„Äç„ÄÇ
- Êèê‰æõËÖ¶Ê¥ûÔºöÁµ¶Âá∫ 3 ÂÄã‰ª•‰∏äÁöÑÂäáÊÉÖËµ∞ÂêëÂª∫Ë≠∞„ÄÇ
- ÂÑ™ÂåñÁàΩÈªûÔºöÂª∫Ë≠∞Â¶Ç‰ΩïËÆìÈÄôÊÆµÂäáÊÉÖÊõ¥„ÄåÁàΩ„Äç„ÄÇ
- Ë±êÂØåÁ¥∞ÁØÄÔºöË£úÂÖÖÁí∞Â¢ÉÊèèÂØ´ÊàñÂøÉÁêÜÊ¥ªÂãï„ÄÇ
Ë™ûÊ∞£Ë¶ÅÁÜ±ÊÉÖ„ÄÅÂÖÖÊªøÈºìÂãµÔºåÂÉèÂÄã‰∏¶ËÇ©‰ΩúÊà∞ÁöÑÊà∞Âèã„ÄÇ`;
            break;

        case 'reader': // The consumer
            specificInstruction = `
„ÄêÁï∂ÂâçÊ®°ÂºèÔºöüî• ÊØíËàåËÆÄËÄÖ (Reader)„Äë
‰Ω†ÁöÑ‰ªªÂãôÊòØ„ÄåÂêêÊßΩ„ÄçËàá„ÄåÂèçÈ•ã„Äç„ÄÇ
- ‰ΩøÁî®ËÄÖÈ´îÈ©óÔºöÈÄôÊÆµÊàë‰∏çÂñúÊ≠°ÔºåÂ§™Ê∞¥‰∫ÜÔºÅ
- ÊúüÂæÖÁÆ°ÁêÜÔºöÈÄôË£°Êñ∑Á´†Êñ∑ÂæóÂ•ΩÔºåÊàëÊúÉÊÉ≥Ë≤∑‰∏ã‰∏ÄÁ´†„ÄÇ
- ÁúüÂØ¶ÊÑüÂèóÔºö‰∏ªËßíÈÄôË£°Â§™ËÅñÊØç‰∫ÜÔºåÁúã‰∫Ü‰∏çÁàΩ„ÄÇ
Ë´ãÊ®°‰ªøËÆÄËÄÖË©ïË´ñÂçÄÁöÑÁúüÂØ¶Ë™ûÊ∞£ÔºàÂåÖÂê´‰∏Ä‰∫õÁ∂≤Ë∑ØÁî®Ë™ûÔºâ„ÄÇ`;
            break;

        case 'plot_architect': // 10-15 Point Dynamic Plot
            specificInstruction = `
„ÄêÁï∂ÂâçÊ®°ÂºèÔºöüèóÔ∏è ÂäáÊÉÖÊû∂ÊßãÂ∏´ (Plot Architect)„Äë
‰Ω†ÁöÑ‰ªªÂãôÊòØÁîüÊàê‰∏Ä‰ªΩ„ÄåÁ¥∞Á∑ªÂåñÁ´†ÁØÄÂ§ßÁ∂±„Äç„ÄÇ
Ë´ãÂö¥Ê†ºÊåâÁÖß‰ª•‰∏ã„Äå10-15 ÈªûÂãïÊÖãÊ®°ÁµÑ„ÄçÊ†ºÂºèËº∏Âá∫ÔºåÂ∞áÁ´†ÁØÄÊãÜËß£ÁÇ∫Á¥∞Á∑ªÁöÑÊÉÖÁØÄÈªû„ÄÇ‰∏çË¶ÅÂè™Áµ¶Âá∫ 3-5 ÈªûÔºåÂøÖÈ†àÊãÜËß£Âà∞ 10 Èªû‰ª•‰∏ä„ÄÇ

Â∏∏Áî®ÊÉÖÁØÄÂÖÉ‰ª∂Â∫´ÔºàË´ãËá™Áî±ÁµÑÂêàÈ†ÜÂ∫èÔºâÔºö
- „ÄêÈñãÂ†¥/ÂãïÊ©ü„Äë(ÂºïÁôº‰∫ã‰ª∂)
- „ÄêÂâçÊúüÊ∫ñÂÇô„Äë(ÂøÉÁêÜ/Áâ©Ë≥á)
- „ÄêË°åÂãïÈÅéÁ®ã„Äë(ÊΩõÂÖ•Á¥∞ÁØÄ/Êà∞È¨•)
- „ÄêÈÅ≠ÈÅáÈöúÁ§ô„Äë(Èô£Ê≥ï/ÂÆàË°õ/Á™ÅÁôºÁãÄÊ≥Å)
- „ÄêÊáâÂ∞ç/ÂèçËΩâ„Äë(Êô∫Âèñ/Á°¨Èóñ/ÊïëÊè¥)
- „ÄêÈ´òÊΩÆ/Ê†∏ÂøÉ„Äë(ÈóúÈçµÊôÇÂàª/Áç≤ÂæóÁâ©ÂìÅ)
- „ÄêÁí∞Â¢ÉÁï∞Ë±°„Äë(‰∏ñÁïåËßÄÂèçÊáâ/Ê∞£Ê∞õÊ∏≤Êüì)
- „ÄêÊí§ÈÄÄ/ÁµêÁÆó„Äë(È©öÈö™ÈÄÉÈõ¢/Êà∞ÂæåÁõ§Èªû)
- „ÄêÈÖçËßí‰∫íÂãï„Äë(Ê≠£Èù¢/ÂÅ¥Èù¢/Â§ö‰∫∫‰∫§‰∫í)
- „ÄêÁµêÂ∞æ/‰ºèÁ≠Ü„Äë(‰∏ãÁ´†È†êÂëä/Êá∏Âøµ)

Ëº∏Âá∫ÁØÑ‰æãÔºö
1. „ÄêÈñãÂ†¥„Äë‰∏ªËßí...
2. „ÄêË°åÂãï„Äë...
...
12. „ÄêÁµêÂ∞æ„Äë...
`;
            break;

        default:
            specificInstruction = "Ë´ãÈùàÊ¥ªÈÅãÁî®‰∏âÁ®ÆË¶ñËßíÔºåÂçîÂä©‰ΩúËÄÖÂÆåÊàêÂâµ‰Ωú„ÄÇ";
    }

    return `${baseIdentity}\n${outputRules}\n${specificInstruction}`;
}

// --- API Routes ---

// GET /api/chat/:novelId/history
router.get('/:novelId/history', async (req, res) => {
    const { novelId } = req.params;
    const { limit = 50, before } = req.query;
    const supabase = req.supabase;

    try {
        let { data: session } = await supabase.from('chat_sessions').select('id').eq('novel_id', novelId).single();
        if (!session) {
            const { data: newSession, error } = await supabase.from('chat_sessions').insert({ novel_id: novelId }).select().single();
            if (error) throw error;
            session = newSession;
        }

        let query = supabase.from('chat_messages').select('*').eq('session_id', session.id).order('created_at', { ascending: false }).limit(parseInt(limit));
        if (before) query = query.lt('created_at', before);

        const { data: messages, error } = await query;
        if (error) throw error;

        res.json({ session_id: session.id, messages: messages.reverse() });
    } catch (error) {
        res.status(500).json({ error: error.message });
    }
});

// POST /api/chat
router.post('/', async (req, res) => {
    const { message, novelId, currentChapterId, model = 'Qwen-Plus', intent = 'chat' } = req.body;
    const supabase = req.supabase;

    try {
        // 1. Session Init
        let { data: session } = await supabase.from('chat_sessions').select('id').eq('novel_id', novelId).single();
        if (!session) {
            const { data: newSession } = await supabase.from('chat_sessions').insert({ novel_id: novelId }).select().single();
            session = newSession;
        }

        // 2. Determine Persona & Model based on Intent
        let targetPersona = 'muse';
        let activeModel = model;

        if (intent === 'plot') {
            targetPersona = 'plot_architect'; // 10-15 point plot
            // Plot generation is complex, prefer Strong Logic (Qwen-Max or R1 or GPT-4)
            if (activeModel === 'DeepSeek V3') activeModel = 'DeepSeek R1';
        } else if (intent === 'critique') {
            targetPersona = 'editor';
            activeModel = 'DeepSeek R1'; // Logic check
        } else if (intent === 'reader_feedback') {
            targetPersona = 'reader';
            activeModel = 'DeepSeek V3'; // Fast feedback
        }

        // 3. Save User Message
        await supabase.from('chat_messages').insert({
            session_id: session.id, role: 'user', content: message,
            model_used: null, context_mode: intent
        });

        // 4. Build Context
        const contextData = await buildChatContext(supabase, novelId, currentChapterId, intent === 'plot' ? 'standard' : 'deep');
        const systemPrompt = buildSystemPersona(targetPersona);

        const fullPrompt = `
${systemPrompt}

„ÄêÂèÉËÄÉË≥áÊñôÂ∫´ (Briefing Brain)„Äë
${contextData}

„ÄêÁî®Êà∂Êåá‰ª§„Äë
${message}
`;

        // 5. Model Execution
        let aiContent = "";
        let tokensIn = 0, tokensOut = 0;

        if (activeModel.includes('DeepSeek')) {
            if (!deepseek) throw new Error("DeepSeek Config Missing");
            const isReasoning = activeModel.includes('R1');
            const dsModel = isReasoning ? 'deepseek-reasoner' : 'deepseek-chat';

            const response = await deepseek.chat.completions.create({
                model: dsModel,
                messages: isReasoning
                    ? [{ role: 'user', content: fullPrompt }]
                    : [{ role: 'system', content: systemPrompt }, { role: 'user', content: `Context:\n${contextData}\n\nUser:\n${message}` }],
                temperature: isReasoning ? undefined : 0.8
            });
            aiContent = response.choices[0].message.content;
            tokensIn = response.usage?.prompt_tokens;
            tokensOut = response.usage?.completion_tokens;

        } else if (activeModel.startsWith('Qwen')) {
            if (!qwen) throw new Error("Qwen Config Missing");
            const response = await qwen.chat.completions.create({
                model: activeModel === 'Qwen-Max' ? 'qwen-max' : 'qwen-plus',
                messages: [
                    { role: 'system', content: systemPrompt },
                    { role: 'user', content: `Context:\n${contextData}\n\nQuery:\n${message}` }
                ]
            });
            aiContent = response.choices[0].message.content;
            tokensIn = response.usage?.total_tokens;
        } else {
            const googleModel = genAI.getGenerativeModel({ model: 'gemini-2.5-flash' });
            const result = await googleModel.generateContent(fullPrompt);
            aiContent = result.response.text();
        }

        // 6. Save AI Response
        const { data: aiMsg } = await supabase.from('chat_messages').insert({
            session_id: session.id, role: 'assistant', content: aiContent,
            model_used: activeModel, context_mode: intent,
            tokens_input: tokensIn, tokens_output: tokensOut
        }).select().single();

        res.json({ message: aiMsg });

    } catch (error) {
        console.error("Chat error:", error);
        res.status(500).json({ error: error.message });
    }
});

module.exports = router;
